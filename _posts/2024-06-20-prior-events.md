---
layout: page
title: Prior Events
author: Sven Cattell
date: 2024-06-10 09:00:00 +0900
category: "opinion"
---T

here have been calls for transparency in ML for years, but they don't usually go anywhere. Model cards are the most successful concept from this movement but, due to the open-ended nature of them, aren't standardized enough for them to be really useful. I think this is partially because they are seen as an end goal by many organizations. Over the last year AI Red Teaming became another end goal, but this is also not standardized or old enough to actually be useful for the public. I think publicly marrying the two in the GRT2, which has already been done in private, should pressure test both. Personally, I'm most interested in the GRT2 to see how the security community interacts with these ideas of reporting from data science.

There are lots of closed door discussions about things like the CFE and the GRT2, but not many people testing these things. Twitter's "[Bias Bounty](https://blog.x.com/engineering/en_us/topics/insights/2021/algorithmic-bias-bounty-challenge)" in 2021 was a competition with specific rules of engagement. CDAO's [bias bounty](/Users/svencattell/code/flaws/_posts/2024-06-20-coordinated-flaws.md) with Bug Crowd is closer, but is still a competition. Once all the prizes are awarded in a competition, the organizers are done. They don't need to justify why an award wasn't issued to everyone who lost. Actual bounty programs do. There are, however, 2 bounty programs for AI systems in place, one at [Google](https://security.googleblog.com/2023/10/googles-reward-criteria-for-reporting.html?m=1) and one at [Microsoft](https://www.microsoft.com/en-us/msrc/bounty-ai). Both are great, and I'm excited to hear what they've learnt. However, both don't include bias and other harms as in-scope. I wouldn't if I were them, due to the aforementioned uncertainties. 

These programs don't prepare our systems for a coordinated disclosure with a scope that includes bias and less tangible harms. The potential award of either money, or a CVE number, to each reporter adds complexity to the competition format predecessors that dealt with bias. . They do, however, prepare us. I feel that the time is perfect to run this. 