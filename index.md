---
layout: home
---

# Event Brief

For DEFCON32, AI Village is hosting GRT2, a generative red teaming challenge in the form of a bug bash. During last year’s GRT1, participants were tasked with identifying flaws within a set of preselected scenarios. This year, we are asking participants to organically evaluate a machine learning model, identify vulnerabilities and flaws, and provide evidence to support the replicability and significance of their findings. Participants will submit flaw reports, which will be assessed by a judging panel and bounties will be paid out throughout the event. We want people to test the structure of red teaming itself so that we can iterate and improve upon these processes.

# How to Participate

1. Sign up to participate in GRT2 by stopping at the AI Village space.
2. Create an account with the Dreadnode team so that you can submit your bug reports. For beginners — async workshops will be running all day at AI Village. These 30 minute workshops will help you get oriented and ready for the bug bash.
3. Red team the LLM model! Make sure to review the model card for details about the model’s intended use and specifications. You can stick around the AI Village or work on GRT2 throughout DEFCON.
4. When you have a submission you want to report to the vendor you have to go through Bug Crowd, so create or log into your Bugcrowd account.
5. Write up your findings and submit your report via Dreadnode’s application.

If you're not at DEFCON, you can do the workshop AISI created remotely. It's on github [here](https://github.com/UKGovernmentBEIS/defcon_grt_notebook/blob/main/quickstart.ipynb), and Here's a [pre-loaded](https://colab.research.google.com/github/UKGovernmentBEIS/defcon_grt_notebook/blob/main/quickstart.ipynb) colab notebook.

**Strong submissions make specific claims about things in the model card that are incorrect, incomplete, or missing. An argument of the form, "The model card says something happens X% of the time, but this shows worse performance of Y%" is best. An argument of the form, "the model card says this, but my submission shows something else," is good.**

# Judging and Rubric

Judging for GRT2 will run from Friday at 10:30 AM PST until Saturday at midnight. Judges will be assessing bug reports for significance and importance. For GRT2, we are interested in “flaws”, which we deem to be behaviors absent or violating in opposition with the Model Card specs. We are asking participants to take a holistic view of safety and security, combining security culture and standards with novel  reports of flaws. For these more unique issues, our adjudication process allows for a conversation with our experts in the event of a disagreement.
